{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7AYJYPJXcPxf"
   },
   "source": [
    "**LeNet for MNIST Handwritten character recognition**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHYFQSt1bCaD"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vT1rL7Rcr64"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "# How to choose between CPU and GPU?\n",
    "# Use torch.cuda.is_available() and torch.device() to assign the device (CPU/GPU) to a variable named device.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1IwMtoVcjcR"
   },
   "outputs": [],
   "source": [
    "torch.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUwvBAHbdX4R"
   },
   "source": [
    "*   cuda.is_available  = [Link](https://pytorch.org/docs/stable/cuda.html#torch.cuda.is_available)\n",
    "*   device = [Link](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2066,
     "status": "ok",
     "timestamp": 1545826601050,
     "user": {
      "displayName": "yogesh rai",
      "photoUrl": "https://lh4.googleusercontent.com/-nxzWnbmf4S0/AAAAAAAAAAI/AAAAAAAAABc/eXuoqHhvASM/s64/photo.jpg",
      "userId": "11667083412188592073"
     },
     "user_tz": -345
    },
    "id": "sPOF_Bqdd-kc",
    "outputId": "ed10cb5e-3491-486c-f8b6-d1f663bfb25b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlIy9LgbbR3L"
   },
   "outputs": [],
   "source": [
    "# Play around with the hyperparams below\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgLQzhWycoE3"
   },
   "outputs": [],
   "source": [
    "# The dataset we are going to work on is MNIST handwritten characters dataset.\n",
    "# Follow the api in the below link to load the MNIST dataset in torchvision.datasets\n",
    "# train_loader and test_loader need to use the dataloader api to have a batch wise data loading function\n",
    "# Try to understand how batch wise training works by thinking about how training was done in the previous ML experiements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXifFff7536M"
   },
   "source": [
    "*   torchvision.datasets.MNIST = [Link](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist)\n",
    "*   torch.utils.data.DataLoader = [Link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9SyvqvJbgy2"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# MNIST dataset\n",
    "# Checkout possible transforms. Data augmentation can help improve accuracy in most cases.\n",
    "# Explore any of the options available. Try to understand what they all do\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                           train=True, \n",
    "                                           transform=##Enter code here##,\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Try to add a cell below to see how the batch loader outputs data\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=##Enter code here##,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--9iRR0u70yT"
   },
   "source": [
    "Lets try to build  the network architecture from the given image.\n",
    "\n",
    "\n",
    "1st layer:\n",
    "\n",
    "Convolution layer:\n",
    "\n",
    ">in_channels = 1\n",
    ">out_channels = 16\n",
    ">kernel_size = 5\n",
    ">stride = 1\n",
    ">padding = 2\n",
    "\n",
    "Batchnorm features = 16\n",
    "\n",
    "Maxpool layer:\n",
    "\n",
    ">kernel size= 2\n",
    ">stride = 2\n",
    " \n",
    " \n",
    "2nd layer:\n",
    "\n",
    "Convolution layer:\n",
    "\n",
    ">in_channels = 16\n",
    ">out_channels = 32\n",
    ">kernel_size = 5\n",
    ">stride = 1\n",
    ">padding = 2\n",
    "\n",
    "Batchnorm features = 32\n",
    "\n",
    "Maxpool layer:\n",
    "\n",
    ">kernel size= 2\n",
    ">stride = 2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpOcpqc97qJx"
   },
   "source": [
    "![alt text](https://pytorch.org/tutorials/_images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5_OmAtxbjwV"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "# What does each layer do? Try to understand the significance of each operation\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(##Enter code here##),\n",
    "            nn.BatchNorm2d(##Enter code here##),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(##Enter code here##))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(##Enter code here##),\n",
    "            nn.BatchNorm2d(##Enter code here##),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(##Enter code here##))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## Design the flow graph here\n",
    "        # x here is the data\n",
    "        # the transformations that need to be done are the 5 layers in sequence.\n",
    "        # You might have to reshape the vector before the fully connected layers\n",
    "        out = ##Enter the code here##\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jo6mBtWPby2n"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "# WHat are the other losses that are available?\n",
    "# Is cross entropy loss the best option?\n",
    "# How should one choose the loss function?\n",
    "# Ask TA or Professor, if you do not answers to these. Must know.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haa7Ttl5b60m"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "      \n",
    "        ## Pytorch has an easy method to convert data format to be compatible between CPU and GPU.\n",
    "        # Convert the data vectors to the \"device\" type\n",
    "        \n",
    "        ## Enter the code here##        \n",
    "        \n",
    "        # Forward pass\n",
    "        # Note how the output is extracted from the network in the line below.\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wRKdgIPb_YV"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85aUFT-WcGYX"
   },
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lenet_MNIST_Day6.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
