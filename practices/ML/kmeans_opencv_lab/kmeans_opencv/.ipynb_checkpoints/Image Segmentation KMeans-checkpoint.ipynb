{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has dependencies on 'Numpy' and 'OpenCV'\n",
    "# Open cmd terminal and run the following command to get them installed (passwd: prime)\n",
    "# \"sudo pip install numpy opencv-python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opencv is a library that supports computer vision algorithms.\n",
    "# Image segmentation is a problem that has a natural correspondence with Clustering\n",
    "# We will look at the use of KMeans in segmenting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will have to upload the 3 images to google colab. We have uploaded files before. Check them for reference\n",
    "# Step 1:\n",
    "# Use the function cv2.imread() to read the original image. (Pick any of your favourite among the 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Reference:\n",
    "[Link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html#read-an-image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88,  87,  85, ...,  86,  86,  86],\n",
       "       [ 88,  87,  85, ...,  83,  84,  84],\n",
       "       [ 87,  86,  85, ...,  80,  82,  83],\n",
       "       ...,\n",
       "       [109, 109, 109, ..., 176, 176, 176],\n",
       "       [109, 109, 109, ..., 175, 175, 175],\n",
       "       [109, 109, 109, ..., 174, 174, 174]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('home.jpg',0)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([88, 87, 85, 84, 84, 85, 87, 88, 86, 86, 86, 86, 86, 86, 86, 86, 85,\n",
       "       85, 85, 86, 86, 87, 87, 87, 87, 87, 87, 86, 86, 85, 85, 85, 87, 88,\n",
       "       88, 88, 88, 87, 86, 85, 85, 85, 85, 85, 85, 85, 85, 85, 84, 84, 84,\n",
       "       84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 84,\n",
       "       84, 83, 83, 83, 84, 84, 84, 83, 83, 82, 82, 82, 81, 81, 81, 81, 81,\n",
       "       81, 81, 81, 83, 83, 83, 82, 82, 81, 81, 81, 79, 80, 80, 81, 81, 82,\n",
       "       82, 83, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 79, 79, 79, 78,\n",
       "       78, 79, 78, 78, 77, 77, 78, 78, 79, 77, 76, 76, 75, 75, 76, 76, 77,\n",
       "       77, 76, 76, 75, 75, 76, 76, 77, 77, 76, 76, 75, 75, 76, 76, 77, 77,\n",
       "       79, 80, 80, 78, 76, 77, 77, 78, 77, 76, 75, 75, 75, 75, 76, 76, 75,\n",
       "       75, 74, 74, 75, 75, 76, 75, 75, 75, 74, 74, 73, 73, 73, 75, 75, 74,\n",
       "       74, 74, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 76, 76, 76, 75,\n",
       "       75, 74, 74, 74, 73, 73, 73, 73, 73, 73, 73, 73, 72, 72, 72, 72, 72,\n",
       "       72, 72, 72, 74, 74, 74, 73, 73, 72, 72, 72, 72, 72, 72, 72, 72, 72,\n",
       "       72, 72, 72, 72, 72, 71, 71, 70, 70, 70, 69, 69, 69, 69, 69, 69, 69,\n",
       "       69, 71, 71, 71, 71, 71, 71, 71, 71, 71, 70, 70, 69, 69, 70, 70, 71,\n",
       "       70, 70, 70, 70, 70, 70, 70, 70, 69, 69, 69, 69, 69, 69, 69, 69, 70,\n",
       "       70, 70, 70, 70, 70, 70, 70, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68,\n",
       "       68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 67, 67,\n",
       "       66, 66, 67, 67, 68, 69, 68, 68, 67, 67, 68, 68, 69, 68, 68, 68, 68,\n",
       "       68, 68, 68, 68, 67, 68, 68, 69, 69, 68, 68, 67, 68, 68, 68, 68, 68,\n",
       "       68, 68, 68, 68, 69, 69, 70, 70, 69, 69, 68, 69, 69, 69, 70, 70, 71,\n",
       "       71, 71, 69, 69, 69, 69, 69, 69, 69, 69, 72, 71, 70, 69, 69, 69, 69,\n",
       "       70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 72, 72, 73, 73, 73,\n",
       "       73, 73, 73, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 73,\n",
       "       75, 77, 79, 80, 79, 77, 76, 76, 75, 75, 75, 75, 76, 77, 78, 78, 77,\n",
       "       77, 77, 77, 78, 79, 80, 80, 80, 80, 81, 81, 82, 82, 82, 81, 81, 82,\n",
       "       83, 84, 84, 85, 86, 83, 83, 83, 83, 83, 83, 83, 83, 86, 85, 83, 82,\n",
       "       81, 81, 82, 83, 80, 79, 77, 78, 80, 80, 79, 78, 80, 80, 80, 80, 80,\n",
       "       80, 80, 80, 81, 80, 78, 77, 77, 78, 80, 81, 81, 82, 83, 85, 86, 86,\n",
       "       86, 86], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Number of Channels\n",
    "# Grayscale images have 1 dimension\n",
    "# Color images have 3 (corresponding to RGB)\n",
    "nchannels = img.ndim\n",
    "nchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale and Color images are stored as [x_dim,y_dim,1], and [x_dim,y_dim,3] matrices respectively.\n",
    "# A commonly used Computer Vision technique to reduce dimensions of image is to \"vectorize\" them.\n",
    "# Meaning [x_dim,y_dim,1] ==> [new_dim,1]  : For Grayscale images\n",
    "# Meaning [x_dim,y_dim,3] ==> [new_dim,3]  : For Color images\n",
    "# How do we do this? Hint (We should \"reshape\" a numpy array)\n",
    "# Why do we need this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88],\n",
       "       [ 87],\n",
       "       [ 85],\n",
       "       ...,\n",
       "       [174],\n",
       "       [174],\n",
       "       [174]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = img.reshape(img.shape[0] * img.shape[1],1)\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196608, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196608, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = vec.copy()\n",
    "Z = np.float32(Z)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have an image vector that can be processed by K-Means algorithm\n",
    "# Study the cv2 documentation for using K-Means and feed in all the required parameters as its input\n",
    "# Note that these parameters decide the quality of your segmentation.\n",
    "# Most of ML is tuning these so-called \"hyperparameters\" and finding the best ones.\n",
    "# Feel free to experiment on these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 8\n",
    "ret, label, center = cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "cv2.imshow('res2',res2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.4) C:\\bld\\opencv_1545175842640\\work\\modules\\core\\src\\kmeans.cpp:240: error: (-215:Assertion failed) data0.dims <= 2 && type == CV_32F && K > 0 in function 'cv::kmeans'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-47a0d663cfce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# p = cv2.kmeans(vec,K=3,criteria=criteria)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriteria\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKMEANS_RANDOM_CENTERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.4) C:\\bld\\opencv_1545175842640\\work\\modules\\core\\src\\kmeans.cpp:240: error: (-215:Assertion failed) data0.dims <= 2 && type == CV_32F && K > 0 in function 'cv::kmeans'\n"
     ]
    }
   ],
   "source": [
    "# p = cv2.kmeans(vec,K=3,criteria=criteria)\n",
    "ret,label,center=cv2.kmeans(Z,2,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Reference:\n",
    "[Link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output parameters are : Compactness, labels, and centers\n",
    "# What do they mean? Would you desire more compactness? Is that always good?\n",
    "# Experiment on different images and hyperparameters and check the quality of segmentation\n",
    "# and try to analyze if compactness is a good measure of clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember cv2.imread() which we used to read an image,in Step 1\n",
    "# Now use cv2.imshow() to show the image that was read in Step 1\n",
    "# This is the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Reference:\n",
    "[Link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html#display-an-image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is good practice to add the following two lines of code when using imshow()\n",
    "# This makes the image display wait until ESC key is pressed\n",
    "# So you can see the image and close it by hitting the ESC key whenever you need to\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the labels array that is the output of K-Means\n",
    "# This is an image vector denoting the cluster assigment of shape [new_dim,1]\n",
    "# How can we transform this into a grayscale image?\n",
    "# This is basically the inverse of \"vectorize\" operation we did at the start\n",
    "# [new_dim,1] ==> [x_dim,y_dim,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also note that image intensity is always between [0->255]\n",
    "# We will have to scale the cluster assignment in label to this range\n",
    "# Meaning, if the cluster assignment was [0,1,2], we should scale it to [0, 127, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now display this image\n",
    "# This should be a grayscale image showing the labelling of K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we show the segmentation result as a color image instead of grayscale?\n",
    "# One way to do this, is to assign the (RGB) intensity values of cluster centroids as the\n",
    "# RGB intensity values of all pixels belonging to that cluster.\n",
    "# Is this always a good way? Think of KMeans convergence and what if the centroids had same color\n",
    "# Lets anyway stick to this approach\n",
    "# To do this, you have to do the following:\n",
    "# For example, consider we have 3 clusters with centroids c0,c1,c2\n",
    "# Now look at all the pixels of the labels image (which stores the cluster assignment -> 0,1,2)\n",
    "# All pixels with label 0, need to have intensity of c0, and so on for 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display this color image showing segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try the other images available, and also see if the same hyperparameter settings do justice to them as well\n",
    "# You can repeat by simply re-running this notebook with new image file and hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
