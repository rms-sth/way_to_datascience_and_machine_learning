{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to get Familiar with :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1) Neuron</h3>\n",
    "<h3>2) Activation Function</h3>\n",
    "<h3>3) How do NN work?</h3>\n",
    "<h3>4) How do NN learn?</h3>\n",
    "<h3>5) Gradient Descent</h3>\n",
    "<h3>6) Stochastic Gradient Descent</h3>\n",
    "<h3>7) Backpropagation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual human neuron in microscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"img/1.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Image from modern Microscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"img/2.png\"> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neurons by themselves are pretty much useless. Its like an ant. An ant\n",
    "on its own can't do much. Five ant together can pick up something much.\n",
    "But they can't build ant hill. But at the same time when you have lots\n",
    "and lots of ants like millions then, they can build the whole colony or\n",
    "anthill. Same thing as Neuron. By itself it's not that strong but when\n",
    "you have lots of neurons together they work together to do magic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do they work together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well thats where dendrites and axon comes for. The dendrites are receivers\n",
    "of the signal for the neuron and the Axon is the transmitter of the signal\n",
    "for the neuron. Lets see in bigger pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/3.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the top we've got the neuron. We can see that its dendrites are connected to axons of other neurons that are like even further away. And the signal from this neuron travels down its axon and connects or passes to the dendrites of the next neuron and that's how they're connected. \n",
    "\n",
    "And in that small image over there, we can see that axon doesn't actually touch the dendrite. A lot of machine learning or like few machine learning scientists are very adamant about the fact that it doesn't touch and it has been proven that there is no physical connection there. But the point that we are interested in is that connection between them i.e. the signal being\n",
    "passed that are called synapse (in little image)\n",
    "\n",
    "So instead of calling our ANN the lines that we are going to have or the connectiors for artificial neurons, we are now going to call them as axons or dendrites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go to how we are going to represent neurons in Machine. Now we are moving away from neuroscience and moving into tecnhonlogy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/4.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image is the neuron also sometimes called as node. Thats the one that gets some input signals and it has an output signal. These input signal are represented as input values. In this specific image, the green neuron is getting signals from yellow neurons. Here yellow nodes are input layer and the green means output layer. Sometimes we'll have neurons which get their signal from other hidden layer neurons i.e other green neurons. and the concept is going to be exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/5.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look deep down detail into these input layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/6.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to remeber here is that these independent variables are all for one single observation. So we can think of it as just one row in our database. It may be age of person, amount of money in their bank account, how they drive or walk , what sampoo's protection do they use etc. But that's all the descriptions of one specific person that you are either training your model on or we're performing some prediction on. \n",
    "\n",
    "One other thing we need to know about these variables is that we need to standarize them which means makes sure they have a mean of zero and variance of on or we can also sometimes want to normalize them meaning that instead of making sure the mean and variance is 1, we just subtract the minimum value - maximum by the range of our values get the values between 0 and 1. And it all depends on the scenerio.\n",
    "\n",
    "But basically we want all of these varibales to be quite similar in about the same range of values.\n",
    "\n",
    "Because all of these values are going to go into our NN where they will be added up and multiplied by weights added up and it's going to be easier for NN to process them if they're about the same. And infact thats just how it is goint to be able to work properly.\n",
    "\n",
    "<h3> Output Values </h3>\n",
    "\n",
    "1) Output values can be continuous like instance price or \n",
    "\n",
    "2) it can be binary like if the person will exit or stay or \n",
    "\n",
    "3) it can be categorical variable and if it is categorical variable the thing to remember here is that our output value won't be just 1. It could be several output values because these will be a dummy variables which will be representing our categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/8.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "The important thing to remember is that whatever inputs we are putting in that's for one row and then the output we get that is for that same exact row. We can think of it as like as a Simple Linear Regression or Multvariate linear Regression wehre we're putting in our values and getting the values for the same row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/9.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synapses are the weights in our ANN\n",
    "Synapes are assigned weights and its very crucial to our Artificial Neural Network functioning because weights are how our neural networks learn. By adjusting the weights our NN decides in every single case what signal is poor and what signal is not important to certain neuron i.e. what signal gets passed along and what signal doesn't get passed along or  what strength or to what extent the signal gets passed along.\n",
    "\n",
    "These weights get adjusted through the process of learning like when we're training our ANN which means we're basically adjusting all of the weights in synapes across our whole NN and thats where Gradient Descent and Back Porgation come into play "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/10.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, what happen in the Neurons?\n",
    "1) First thing is that all of these values that it's getting get added up so it takes that added weighted sum of all of the input values that is getting ie. add up and multiply by weight.\n",
    "\n",
    "2) It then applies an activation function. An activation function is the function that is assigned to this neuron or to this whole layer and it is applied to this weighted sum. And then, from that the neuron understands if it needs to pass on signal or to not to pass on the signal on which is what exactly happens in step 3.\n",
    "\n",
    "3) The neuron passes on that signal to next nuron down the line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/11.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'img/12.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/7.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Activation Function\n",
    "There are four predominent different types of Activation functions:<br><b>\n",
    "1) Threshold Function<br>\n",
    "2) Sigmoid Function<br>\n",
    "3) ReLu Fuction<br>\n",
    "4) Hyperbolic Tangent Function<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Threshold Function:\n",
    "On X-axis we have weighted sum of inputs nad on Y- Axis we have just the values 0 to 1. It is very simple type of function where if the value is less than 0 than threshold function passes on 0. If the value is more than 0 or equal to 0 then, threshold functions passes on 1. It's basically like yes or no type of function which is very very straight forword i.e. either yes or no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/13.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The Sigmoid Function:\n",
    "It is very interesting formula where here x is the value of sum of weights. It is used in Logistic Regression. What's good about this function is that it is smooth. Unlike thresold function it doesn't have those kinks in its curve and therefore it's just nice and smooth gradual progression. This sigmoid function is very useful in final output layer. Specially when we're trying to predict probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/14.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Rectified Function:\n",
    "Even though it has a kink, it is one of the most popular function for ANN. It goes all the way to 0 and from there it gradually progresses as the input value increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/15.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Hyperbolic Tangent Function:\n",
    "It is very similar to the Sigmoid Function but here the hyperbolic tangent function goes below 0, so the values go from 0 to 1 or approximately to 1 and go from 0 to -1 on the other side. This can be useful in some applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/16.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/17.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question : Assuming that your dependent variable is binary i.e 0 or 1 which threshold function would you use?\n",
    "Answer :\n",
    "    \n",
    "<b>1) Threshold function :</b>\n",
    "We know that it's between 0 and 1 and gives us 0 under certain values and then otherwise it give us 1 ie. it can given only two values. It will perfectly fit this requirement\n",
    "    \n",
    "<b>2) Sigmoid function :</b>\n",
    "It is actually also between 0 and 1. But at the same time we want is just 0 and 1. It's not exactly what we need but in this case what we could use it as is the probabilty of y being yes or no. And it's very similar to logisitc regression approach3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/18.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Practical Application of Activation function:</b>\n",
    "\n",
    "1) Input layers we have some inputs. They are sent to our hidden layer.\n",
    "\n",
    "2) An activation function is appiled. And usually what we would apply here Rectified Activation function.\n",
    "\n",
    "3) Then from there the signal would passed on to the output layer where the sigmoid activation function would be applied which would be our final output value. And it could predict a probability for instance.\n",
    "\n",
    "Summary: In hidden layer we apply ReLu function and then in output layer we apply the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/19.png'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
