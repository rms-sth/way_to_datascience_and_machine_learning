{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "A lot of resources are mentioned here: http://mccormickml.com/2016/04/27/word2vec-resources/\n",
    "\n",
    "As we know, CBOW is learning to predict the word by the context. Or maximize the probability of the target word by looking at the context. And this happens to be a problem for rare words. For example, given the context `yesterday was a really [...] day` CBOW model will tell you that most probably the word is `beautiful` or `nice`. Words like `delightful` will get much less attention of the model, because it is designed to predict the most probable word. This word will be smoothed over a lot of examples with more frequent words.\n",
    "\n",
    "On the other hand, the skip-gram model is designed to predict the context. Given the word `delightful` it must understand it and tell us that there is a huge probability that the context is `yesterday was really [...] day`, or some other relevant context. With skip-gram the word delightful will not try to compete with the word beautiful but instead, delightful+context pairs will be treated as new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "\n",
    "# Continuous Bag of Words model\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, context_size=2, embedding_size=100, vocab_size=None):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.linear1 = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        lookup_embeds = self.embeddings(inputs)\n",
    "        embeds = lookup_embeds.sum(dim=0)\n",
    "        out = self.linear1(embeds)\n",
    "        out = F.log_softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "EMBEDDING_SIZE = 10\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower().split()\n",
    "\n",
    "# How could you do a better pre-processing?\n",
    "# Maybe a sentence tokenizer?\n",
    "# Maybe a word lemmatizer?\n",
    "# Should you take a bigger corpus, Replace this small corpus with a bigger one\n",
    "# Maybe you should remove stopwords\n",
    "# Maybe you should just Google?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['we', 'are', 'to', 'study'], 'about')\n"
     ]
    }
   ],
   "source": [
    "# Create the  vocabulary\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "\n",
    "print (data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch  0  :  tensor(255.9591)\n",
      "Loss for epoch  1  :  tensor(226.5571)\n",
      "Loss for epoch  2  :  tensor(203.5022)\n",
      "Loss for epoch  3  :  tensor(185.3333)\n",
      "Loss for epoch  4  :  tensor(170.6402)\n",
      "Loss for epoch  5  :  tensor(158.3100)\n",
      "Loss for epoch  6  :  tensor(147.6673)\n",
      "Loss for epoch  7  :  tensor(138.3020)\n",
      "Loss for epoch  8  :  tensor(129.9490)\n",
      "Loss for epoch  9  :  tensor(122.4272)\n",
      "Loss for epoch  10  :  tensor(115.6029)\n",
      "Loss for epoch  11  :  tensor(109.3704)\n",
      "Loss for epoch  12  :  tensor(103.6462)\n",
      "Loss for epoch  13  :  tensor(98.3646)\n",
      "Loss for epoch  14  :  tensor(93.4732)\n",
      "Loss for epoch  15  :  tensor(88.9299)\n",
      "Loss for epoch  16  :  tensor(84.6992)\n",
      "Loss for epoch  17  :  tensor(80.7513)\n",
      "Loss for epoch  18  :  tensor(77.0601)\n",
      "Loss for epoch  19  :  tensor(73.6033)\n",
      "Loss for epoch  20  :  tensor(70.3612)\n",
      "Loss for epoch  21  :  tensor(67.3165)\n",
      "Loss for epoch  22  :  tensor(64.4538)\n",
      "Loss for epoch  23  :  tensor(61.7596)\n",
      "Loss for epoch  24  :  tensor(59.2216)\n",
      "Loss for epoch  25  :  tensor(56.8288)\n",
      "Loss for epoch  26  :  tensor(54.5709)\n",
      "Loss for epoch  27  :  tensor(52.4388)\n",
      "Loss for epoch  28  :  tensor(50.4238)\n",
      "Loss for epoch  29  :  tensor(48.5179)\n",
      "Loss for epoch  30  :  tensor(46.7137)\n",
      "Loss for epoch  31  :  tensor(45.0044)\n",
      "Loss for epoch  32  :  tensor(43.3835)\n",
      "Loss for epoch  33  :  tensor(41.8450)\n",
      "Loss for epoch  34  :  tensor(40.3834)\n",
      "Loss for epoch  35  :  tensor(38.9934)\n",
      "Loss for epoch  36  :  tensor(37.6704)\n",
      "Loss for epoch  37  :  tensor(36.4097)\n",
      "Loss for epoch  38  :  tensor(35.2074)\n",
      "Loss for epoch  39  :  tensor(34.0595)\n",
      "Loss for epoch  40  :  tensor(32.9625)\n",
      "Loss for epoch  41  :  tensor(31.9131)\n",
      "Loss for epoch  42  :  tensor(30.9083)\n",
      "Loss for epoch  43  :  tensor(29.9452)\n",
      "Loss for epoch  44  :  tensor(29.0214)\n",
      "Loss for epoch  45  :  tensor(28.1345)\n",
      "Loss for epoch  46  :  tensor(27.2822)\n",
      "Loss for epoch  47  :  tensor(26.4625)\n",
      "Loss for epoch  48  :  tensor(25.6737)\n",
      "Loss for epoch  49  :  tensor(24.9140)\n",
      "Loss for epoch  50  :  tensor(24.1820)\n",
      "Loss for epoch  51  :  tensor(23.4761)\n",
      "Loss for epoch  52  :  tensor(22.7952)\n",
      "Loss for epoch  53  :  tensor(22.1381)\n",
      "Loss for epoch  54  :  tensor(21.5037)\n",
      "Loss for epoch  55  :  tensor(20.8911)\n",
      "Loss for epoch  56  :  tensor(20.2995)\n",
      "Loss for epoch  57  :  tensor(19.7281)\n",
      "Loss for epoch  58  :  tensor(19.1761)\n",
      "Loss for epoch  59  :  tensor(18.6429)\n",
      "Loss for epoch  60  :  tensor(18.1280)\n",
      "Loss for epoch  61  :  tensor(17.6307)\n",
      "Loss for epoch  62  :  tensor(17.1506)\n",
      "Loss for epoch  63  :  tensor(16.6872)\n",
      "Loss for epoch  64  :  tensor(16.2401)\n",
      "Loss for epoch  65  :  tensor(15.8087)\n",
      "Loss for epoch  66  :  tensor(15.3926)\n",
      "Loss for epoch  67  :  tensor(14.9914)\n",
      "Loss for epoch  68  :  tensor(14.6046)\n",
      "Loss for epoch  69  :  tensor(14.2318)\n",
      "Loss for epoch  70  :  tensor(13.8725)\n",
      "Loss for epoch  71  :  tensor(13.5264)\n",
      "Loss for epoch  72  :  tensor(13.1929)\n",
      "Loss for epoch  73  :  tensor(12.8716)\n",
      "Loss for epoch  74  :  tensor(12.5620)\n",
      "Loss for epoch  75  :  tensor(12.2638)\n",
      "Loss for epoch  76  :  tensor(11.9764)\n",
      "Loss for epoch  77  :  tensor(11.6995)\n",
      "Loss for epoch  78  :  tensor(11.4327)\n",
      "Loss for epoch  79  :  tensor(11.1754)\n",
      "Loss for epoch  80  :  tensor(10.9274)\n",
      "Loss for epoch  81  :  tensor(10.6882)\n",
      "Loss for epoch  82  :  tensor(10.4575)\n",
      "Loss for epoch  83  :  tensor(10.2349)\n",
      "Loss for epoch  84  :  tensor(10.0200)\n",
      "Loss for epoch  85  :  tensor(9.8125)\n",
      "Loss for epoch  86  :  tensor(9.6122)\n",
      "Loss for epoch  87  :  tensor(9.4186)\n",
      "Loss for epoch  88  :  tensor(9.2315)\n",
      "Loss for epoch  89  :  tensor(9.0506)\n",
      "Loss for epoch  90  :  tensor(8.8757)\n",
      "Loss for epoch  91  :  tensor(8.7065)\n",
      "Loss for epoch  92  :  tensor(8.5427)\n",
      "Loss for epoch  93  :  tensor(8.3841)\n",
      "Loss for epoch  94  :  tensor(8.2306)\n",
      "Loss for epoch  95  :  tensor(8.0818)\n",
      "Loss for epoch  96  :  tensor(7.9376)\n",
      "Loss for epoch  97  :  tensor(7.7978)\n",
      "Loss for epoch  98  :  tensor(7.6622)\n",
      "Loss for epoch  99  :  tensor(7.5307)\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "net = CBOW(CONTEXT_SIZE, embedding_size=EMBEDDING_SIZE, vocab_size=vocab_size)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# The training loop\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_var = make_context_vector(context, word_to_ix)\n",
    "        net.zero_grad()\n",
    "        ## Enter code to get log_probs from model\n",
    "        target = autograd.Variable(torch.LongTensor([word_to_ix[target]]))\n",
    "        loss = loss_func(log_probs.reshape(1,-1), target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "    print(\"Loss for epoch \", epoch, \" : \", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's find embedding for every word\n",
    "vocab_to_embedding = {}\n",
    "for word in vocab:\n",
    "    vocab_to_embedding[word] = net.embeddings.forward(make_context_vector([word], word_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_words(word, k = 5):\n",
    "    word = word.lower()\n",
    "    if word not in vocab:\n",
    "        print (\"Not found \", word)\n",
    "        return []\n",
    "    a = vocab_to_embedding[word]\n",
    "    max_sim = -1\n",
    "    sim_here = {}\n",
    "    for b in vocab_to_embedding:\n",
    "        emb = vocab_to_embedding[b]\n",
    "        sim = torch.dot(a.reshape(-1),emb.reshape(-1))/(a.norm()*emb.norm())\n",
    "        sim_here[b] = sim.data[0]\n",
    "    sorted_t = sorted(sim_here.items(), key=operator.itemgetter(1))\n",
    "    sorted_t.reverse()\n",
    "    return sorted_t[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('program.', tensor(1.)),\n",
       " ('other', tensor(0.5284)),\n",
       " ('processes', tensor(0.4700)),\n",
       " ('a', tensor(0.4521)),\n",
       " ('our', tensor(0.3823))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_k_similar_words('program.', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Could you define a Skip Gram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
