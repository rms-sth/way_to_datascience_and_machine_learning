{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4w4PRWgfC9t"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E05lIOwn_2KO"
   },
   "source": [
    "**Intro to Variational Autoencoders**\n",
    "\n",
    "Autoencoders are neural networks that aims to copy their inputs to their outputs. They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.This kind of network is composed of two parts :\n",
    "\n",
    "1.  Encoder: This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).\n",
    "2.  Decoder: This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bi0O1uar_zPz"
   },
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/1*PVm-Y50e3HPOsD9my2sv4A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grviWIOGAT18"
   },
   "source": [
    "Variational Autoencoders can be thought of as an extension of Autoencoder algorithms that allow for learning distributions of data by adapting the network to perform variational inference that we learned about today in class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzaXdUcBBUGE"
   },
   "source": [
    "![alt text](http://kvfrans.com/content/images/2016/08/vae.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wWcZiH_Bdyd"
   },
   "source": [
    "In today's lab let's see how we can train a VAE on the familiar MNIST image dataset. Remember that the objective of VAE is to learn the distribution of the dataset and not just merely reconstructing the images. It would be helpful to keep the ideas of Variational Inference and the reparameterization trick, at the back of your mind while working on this experiment to have a thorough understanding of VAEs and Bayesian Neural Nets in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXMoy09-CV5z"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dXaHnhPeoky"
   },
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Batch size\n",
    "bs = 100\n",
    "\n",
    "## Load the MNIST dataset and apply tensor-transformation to both train and test data \n",
    "## Hint: Checkout documentation for \"torchvision.datasets.MNIST()\"\n",
    "# MNIST Dataset\n",
    "'''\n",
    "ENTER THE CODE HERE\n",
    "'''\n",
    "\n",
    "## Setup a batch loader to fetch data batch by batch\n",
    "## Hint: Checkout \"torch.utils.data.DataLoader()\"\n",
    "# Data Loader (Input Pipeline)\n",
    "'''\n",
    "ENTER THE CODE HERE\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuJCGSVneolB"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        ## The encoder has to be a fully connected network with the following dimensions\n",
    "        ## x_dim -> h_dim1 -> h_dim2\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''\n",
    "        \n",
    "        ## Sample mean and standard deviation with fully connected layers as\n",
    "        ## Mean : h_dim2 -> z_dim\n",
    "        ## Standard deviation : h_dim2 -> z_dim\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''\n",
    "\n",
    "        # decoder part\n",
    "        ## Decoder net has fully connected layers of the following shapes\n",
    "        ## z_dim -> h_dim2 -> h_dim1 -> x_dim\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        ## Relu at the right points\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''    \n",
    "        \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        ## ReLu at the right points. FInaloutput has to have a sigmoid activation\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBDUeaUleolJ"
   },
   "outputs": [],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u4bSGBK4eolX"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    ## calculate Binary cross entropy between recon_x and x\n",
    "    '''\n",
    "    ENTER THE CODE HERE\n",
    "    '''\n",
    "    \n",
    "    ## The following is the closed form solution to compute KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g38p4K5ieole"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## Pass \"data\" as input to \"vae\" and collect the output -> \"recon_batch, mu, log_var\"\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        ## Start the backpropagation here.\n",
    "        ## backward() on what?\n",
    "        '''\n",
    "        ENTER THE CODE HERE\n",
    "        '''\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ak7lkclLeolk"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-OVDJ95eolq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD7Y5ESDeol2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2).cuda()\n",
    "    sample = vae.decoder(z).cuda()\n",
    "    #print(sample.shape)\n",
    "    sample=sample.view(64,28,28,1)[4].cpu().numpy()\n",
    "    print(sample.shape)\n",
    "    #save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')\n",
    "    cv2.imwrite('1.png',sample)\n",
    "    from google.colab import files\n",
    "    files.download('1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sa8mBk25gqkr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_mnist",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
